{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5622311c",
   "metadata": {},
   "source": [
    "###  Q1. What is anomaly detection and what is its purpose?\n",
    "\n",
    "Ans- Anomaly detection is a machine learning and data mining technique used to identify unusual patterns or data points that do not conform to expected behavior within a dataset. Its purpose is to flag or identify instances that deviate significantly from the norm, potentially indicating errors, fraud, or other interesting and unusual events."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81f4b467",
   "metadata": {},
   "source": [
    "### Q2. What are the key challenges in anomaly detection?\n",
    "\n",
    "Ans-  Key challenges in anomaly detection include:\n",
    "\n",
    "1. Lack of labeled data: In many cases, anomalies are rare, making it challenging to collect sufficient labeled examples for supervised learning.\n",
    "2. Imbalanced datasets: Anomalies are often a minority class, leading to class imbalance issues in supervised approaches.\n",
    "3. Data dimensionality: High-dimensional data can make it difficult to define what constitutes an anomaly or to visualize the data effectively.\n",
    "4. Concept drift: Data distributions may change over time, requiring the model to adapt to new patterns of anomalies.\n",
    "5. Noise and variability: Real-world data can be noisy, and anomalies may exhibit varying levels of deviation from the norm.\n",
    "6. Interpretability: Understanding why a data point is flagged as an anomaly is important in practical applications."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "072594d3",
   "metadata": {},
   "source": [
    "### Q3. How does unsupervised anomaly detection differ from supervised anomaly detection?\n",
    "\n",
    "Ans- Unsupervised anomaly detection involves identifying anomalies in a dataset without using labeled examples. It aims to find patterns that differ from the majority of data points. In contrast, supervised anomaly detection requires labeled examples of both normal and anomalous data points for training a model to classify new data points as either normal or anomalous based on the learned patterns."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0e4db53",
   "metadata": {},
   "source": [
    "### Q4. What are the main categories of anomaly detection algorithms?\n",
    "\n",
    "Ans- The main categories of anomaly detection algorithms are:\n",
    "\n",
    "1. Statistical Methods: These methods use statistical techniques to model the distribution of normal data and flag deviations from this distribution.\n",
    "2. Machine Learning-Based Methods: These methods involve the use of machine learning algorithms to train models that can identify anomalies.\n",
    "3. Distance-Based Methods: These methods calculate distances or similarities between data points and use thresholds to detect anomalies.\n",
    "4. Clustering-Based Methods: These methods cluster data points and consider data points in sparse clusters as anomalies.\n",
    "5. Density-Based Methods: These methods estimate the density of data points and flag points in low-density regions as anomalies."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cedcc7fa",
   "metadata": {},
   "source": [
    "### Q5. What are the main assumptions made by distance-based anomaly detection methods?\n",
    "\n",
    "Ans- Distance-based anomaly detection methods assume that anomalies are located far away from the majority of normal data points in the feature space. They typically involve calculating distances or similarities between data points and setting a threshold to classify points as anomalies if their distance/similarity exceeds this threshold."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72092b23",
   "metadata": {},
   "source": [
    "### Q6. How does the LOF algorithm compute anomaly scores?\n",
    "\n",
    "Ans- The Local Outlier Factor (LOF) algorithm computes anomaly scores as follows:\n",
    "\n",
    "1. For each data point, it calculates the density of the data points in its vicinity (local density).\n",
    "2. It compares the local density of the data point with the local densities of its neighbors. If a data point has a significantly lower local density compared to its neighbors, it is considered an anomaly."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e00c7f6",
   "metadata": {},
   "source": [
    "### Q7. What are the key parameters of the Isolation Forest algorithm?\n",
    "\n",
    "Ans-  The key parameters of the Isolation Forest algorithm include:\n",
    "\n",
    "1. Number of Trees (n_estimators): The number of decision trees to build in the forest.\n",
    "2. Maximum Tree Depth (max_depth): The maximum depth of each decision tree.\n",
    "3. Subsample Size (max_samples): The number of data points to be sampled and used for building each tree.\n",
    "4. Random Seed: A seed value for initializing the random number generator for reproducibility."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74131e68",
   "metadata": {},
   "source": [
    "### Q8. If a data point has only 2 neighbours of the same class within a radius of 0.5, what is its anomaly score  using KNN with K=10?\n",
    "\n",
    "Ans- To compute the anomaly score of a data point using K-nearest neighbors (KNN) with K=10 and only 2 neighbors of the same class within a radius of 0.5, the data point would likely have a high anomaly score. It has few neighbors of the same class in its vicinity, which suggests that it is an outlier in the dataset.A high LOF score for data point A indicates that it is an outlier because its local reachability density is much lower than the average reachability density of its neighbors. In the context you provided (K=10 and only 2 neighbors of the same class within a radius of 0.5), if A has only 2 neighbors within a radius of 0.5 and K=10, it is likely to have a high LOF score, suggesting that it is an outlier."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96d5fc42",
   "metadata": {},
   "source": [
    "# Anomaly Score Formula is: s(x,n)=2−c(n)E(h(x))​\n",
    "\n",
    "where s(x,n) is the anomaly score of a data point x in a dataset of size n, E(h(x)) is the average path length of x over a forest of trees, and c(n) is the average path length of an unsuccessful search in a binary tree."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b0cd05e",
   "metadata": {},
   "source": [
    "### Q9. Using the Isolation Forest algorithm with 100 trees and a dataset of 3000 data points, what is the  nomaly score for a data point that has an average path length of 5.0 compared to the average path  length of the trees?\n",
    "\n",
    "Ans- The Isolation Forest algorithm calculates anomaly scores based on the average path length of a data point in multiple decision trees. In this case, a data point with an average path length of 5.0 (compared to the average path length of the trees) would likely have a lower anomaly score. A shorter average path length indicates that the data point is easier to isolate in the trees, suggesting that it is closer to the normal data points and less likely to be an anomaly.\n",
    "A higher anomaly score would indicate a higher chance of being an outlier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80ad742a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
